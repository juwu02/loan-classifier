{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_loan_classifier_rudimentary.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "1Eaoow8Kr5oP",
        "L5uOcqlytPRB",
        "upV0uVEJr3qP",
        "5-3Vtual0q_e",
        "IZAmFF45sID3",
        "XFwBbbYcNSQk",
        "JcvvcdW6sMNm",
        "SvBBKKmeVJLZ",
        "Kg-KpU36GssK",
        "yLTc00h5sUQB",
        "UHZAAiwd7HCf",
        "QmLnY-sTsYWY",
        "sXZBAdjxscUB",
        "MWP_qQhrR2b2",
        "cdWEVi51TNcg",
        "cGMv9AC82fWL"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Eaoow8Kr5oP"
      },
      "source": [
        "# Chapter 1_2: Build a loan-approval classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5uOcqlytPRB"
      },
      "source": [
        "# 1. Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjZsPeOOcyDc"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "pd.set_option('max_colwidth', 5000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sweetviz"
      ],
      "metadata": {
        "id": "GyVkobmziVzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sweetviz"
      ],
      "metadata": {
        "id": "3terhwjuEXHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upV0uVEJr3qP"
      },
      "source": [
        "# 2. Load and inspect the data\n",
        "You have to first upload the loan_approval.csv\n",
        "\n",
        "(original source of data: https://www.kaggle.com/sethirishabh/finance-company-loan-data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BafgGzINc_Fy"
      },
      "source": [
        "%%script echo skip\n",
        "\n",
        "# load the CSV data to a Pandas dataframe\n",
        "df = pd.____('loan_approval.csv')\n",
        "# show the first two rows of the dataframe\n",
        "display(df.____(2))\n",
        "# show detailed information about column names, data types and missing values\n",
        "print(df.____())\n",
        "# 'Loan_Status' is the label: show a bar-chart of the class frequencies\n",
        "df['Loan_Status'].____().plot(kind='____')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Solution\n",
        "# load the CSV data to a Pandas dataframe\n",
        "df = pd.read_csv('loan_approval.csv')\n",
        "# show the first two rows of the dataframe\n",
        "display(df.head(2))\n",
        "# show detailed information about column names, data types and missing values\n",
        "print(df.info())\n",
        "# 'Loan_Status' is the label: show a bar-chart of the class frequencies\n",
        "df['Loan_Status'].value_counts().plot(kind='bar')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "vLuiFw0HQXWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optional: Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "5-3Vtual0q_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_config = sweetviz.FeatureConfig(skip='Loan_ID', force_num=['Loan_Amount_Term'])\n",
        "my_report = sweetviz.analyze(\n",
        "    [df,'Dataset'],\n",
        "    target_feat='Loan_Status',\n",
        "    feat_cfg=feature_config)\n",
        "my_report.show_notebook()"
      ],
      "metadata": {
        "id": "6AtOgpaflo5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZAmFF45sID3"
      },
      "source": [
        "# 3. Build the model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extra: Rudimentary Data Preprocessing\n",
        "We can build a model only with features that are numeric and contain no missing values"
      ],
      "metadata": {
        "id": "XFwBbbYcNSQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# select only the numeric columns\n",
        "selected_columns = ['ApplicantIncome',\n",
        "                    'CoapplicantIncome',\n",
        "                    'LoanAmount',\n",
        "                    'Loan_Amount_Term',\n",
        "                    'Credit_History',\n",
        "                    'Loan_Status']\n",
        "df = df[selected_columns]\n",
        "\n",
        "# remove rows with any missing values\n",
        "df = df.dropna(how='any')\n",
        "\n",
        "# inspect number of remaining rows\n",
        "print(f'num rows after dropna: {len(df)}')"
      ],
      "metadata": {
        "cellView": "code",
        "id": "d7bwvaz9P8EC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcvvcdW6sMNm"
      },
      "source": [
        "## 3.1 Training/Test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qef9QpO1ghLS"
      },
      "source": [
        "%%script echo skip\n",
        "\n",
        "# 80%/20% stratified split (use class label for stratification)\n",
        "X_train, X_test, Y_train, Y_test = ____(df.____(columns=['____']),\n",
        "                                                    df['____'],\n",
        "                                                    test_size=____,\n",
        "                                                    random_state=42,\n",
        "                                                    ____=df['Loan_Status'])\n",
        "\n",
        "# show the number of rows in training and test sets\n",
        "print(f'Number of rows in Training Data: {len(____)}')\n",
        "print(f'Number of rows in Test Data: {len(____)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Solution\n",
        "# 80%/20% stratified split (use class label for stratification)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(df.drop(columns=['Loan_Status']),\n",
        "                                                    df['Loan_Status'],\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=42,\n",
        "                                                    stratify=df['Loan_Status'])\n",
        "\n",
        "# show the number of rows in training and test sets\n",
        "print(f'Number of rows in Training Data: {len(X_train)}')\n",
        "print(f'Number of rows in Test Data: {len(X_test)}')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "QncgRjd8U0VL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optional: Verify that the training/test split is stratified\n",
        "\n",
        "Finds the number of cases per label value in the training and test sets, and divides them by the corresponding number of rows, in order to verify that the proportios of the label values in the two sets are comparable."
      ],
      "metadata": {
        "id": "SvBBKKmeVJLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y_train.value_counts()/len(Y_train))\n",
        "print(Y_test.value_counts()/len(Y_test))"
      ],
      "metadata": {
        "cellView": "code",
        "id": "AyK_DETbVTqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Generate features\n",
        "Not required (features are already available)"
      ],
      "metadata": {
        "id": "Kg-KpU36GssK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLTc00h5sUQB"
      },
      "source": [
        "## 3.3 Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gFWOm5_g21e"
      },
      "source": [
        "%%script echo skip\n",
        "\n",
        "# define model type and hyper-parameter values\n",
        "model = LogisticRegression(C=1,\n",
        "                           max_iter=10**5,\n",
        "                           class_weight={'Y':0.5, 'N':0.5},\n",
        "                           random_state=42)\n",
        "\n",
        "# fit the model to the training data\n",
        "model.____(____, ____)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Solution\n",
        "# define model type and hyper-parameter values\n",
        "model = LogisticRegression(C=1,\n",
        "                           max_iter=10**5,\n",
        "                           class_weight={'Y':0.5, 'N':0.5},\n",
        "                           random_state=42)\n",
        "\n",
        "# fit the model to the training data\n",
        "model.fit(X_train, Y_train)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "pvxbbowesaCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHZAAiwd7HCf"
      },
      "source": [
        "## 3.4 Train a baseline\n",
        "Use \"most_frequent\" as strategy (see documentation of [DummyClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sTVj4DT7F30",
        "cellView": "code"
      },
      "source": [
        "%%script echo skip\n",
        "\n",
        "baseline = ____(strategy=\"____\")\n",
        "baseline.____(____, _____)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Solution\n",
        "baseline = DummyClassifier(strategy=\"most_frequent\")\n",
        "baseline.fit(X_train, Y_train)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "z2diQyicsqOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmLnY-sTsYWY"
      },
      "source": [
        "## 3.5 Generate predictions for the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBfZDnuMh1gg"
      },
      "source": [
        "%%script echo skip\n",
        "\n",
        "# generate predictions with the model\n",
        "Y_pred = ____.____(____)\n",
        "# generate predictions with the baseline\n",
        "Y_pred_baseline = ____.____(____)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Solution\n",
        "# generate predictions with the model\n",
        "Y_pred = model.predict(X_test)\n",
        "# generate predictions with the baseline\n",
        "Y_pred_baseline = baseline.predict(X_test)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "iROSV7lb15RV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXZBAdjxscUB"
      },
      "source": [
        "# 4. Evaluate the predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extra: Prediction Accuracy\n",
        "Measure how frequently the predicted label is equal to the groundtruth by using the function [accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)"
      ],
      "metadata": {
        "id": "MWP_qQhrR2b2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%script echo skip\n",
        "\n",
        "# accuracy of model\n",
        "model_accuracy = ____(____, Y_test)\n",
        "print(f'model accuracy: {np.round(____*100, 2)}')\n",
        "\n",
        "# accuracy of baseline\n",
        "baseline_accuracy = ____(____, Y_test)\n",
        "print(f'baseline accuracy: {np.round(baseline_accuracy*100, 2)}')"
      ],
      "metadata": {
        "id": "yQ0mEMNnSDfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Solution\n",
        "# accuracy of model\n",
        "model_accuracy = accuracy_score(Y_pred, Y_test)\n",
        "print(f'model accuracy: {np.round(model_accuracy*100, 2)}')\n",
        "\n",
        "# accuracy of baseline\n",
        "baseline_accuracy = accuracy_score(Y_pred_baseline, Y_test)\n",
        "print(f'baseline accuracy: {np.round(baseline_accuracy*100, 2)}')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xfJ9WZEuVRla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Evaluation with Confusion Matrix"
      ],
      "metadata": {
        "id": "cdWEVi51TNcg"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MopUpFV4iE0M"
      },
      "source": [
        "def plot_confusion_matrix(confusion_matrix, class_labels):\n",
        "  ax= plt.subplot()\n",
        "\n",
        "  sns.heatmap(confusion_matrix, annot=True, fmt='', cmap='Blues')\n",
        "  ax.set_xlabel('Predicted')\n",
        "  ax.set_ylabel('Actual');\n",
        "  ax.xaxis.set_ticklabels(class_labels)\n",
        "  ax.yaxis.set_ticklabels(class_labels);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pH5iSdRm7zTC"
      },
      "source": [
        "cf_matrix = confusion_matrix(Y_test, Y_pred)\n",
        "plot_confusion_matrix(cf_matrix, list(model.classes_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNrh8UbM73DJ"
      },
      "source": [
        "cf_matrix_baseline = confusion_matrix(Y_test, Y_pred_baseline)\n",
        "plot_confusion_matrix(cf_matrix_baseline, list(baseline.classes_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Open questions\n",
        "*   Have we lost too many training data with dropna()? What can we do about it?\n",
        "*   We were forced to remove all non-numeric columns; how can we avoid this?\n",
        "*   Does the model present acceptable predictive accuracy for both classes?\n",
        "*   Try the \"uniform\" strategy of DummyClassifier and interpret the result\n",
        "*   How can we find the best values for the hyper-parameters of the model?\n",
        "> Try experimenting with C = 0.5 and class_weight = {'Y':0.22, 'N':0.78  (in 3.3 Train the model).\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cGMv9AC82fWL"
      }
    }
  ]
}